Основы статистического анализа данных: .

      Измерение данных .
      Основные типы данных в стат анализе .
      Способы представления данных .
      Оценка параметров распределения случайных величин .
      Основные числовые характеристики .

  целевой показатель - .
    будем рассчитывать его зависимость исходя из остальных данных. Это построение модели.
    если сами собираем информацию - ихсодя из модели планируем, какие дданные нам могут понадобиться.
    если работаем с готовым датасетом - значит работаем с готовым датасетом.
  Тип данных зависит от того, какой шкалой он представлен: .
    Неметрические шкалы: .
      * номинативная (качественная, номинальная, классификационная)
      самая слабая по дифф способности. Нет упорядоченности - нет информации что лучше что хуже.
      |==, !=| 
      * порядковая (ранговая, орденальная)
      объекты упорядочены, но нет информации на сколько больше(лучше)/меньше(хуже), отсутствует интервальность.
      нельзя расчитывать дисперсии, средне квадратическое, коэф симметрии, экспцесса и т.д.   
      |==, !=, <>|

    Метрические шкалы: .
      * интервальная (например  температуры)
      |==, !=, <>, +, -|
      * шкала разностей (например  год, сутки)
      |==, !=, <>, +, -|
      * шкала отношений (например  вес. длина, цена)
      |==, !=, <>, +, -, *, /|
      * абсолютная шкала  (например количество)
      |==, !=, <>, +, -, *, /|
      во всех этих шкалах присутствует интервальность - мы можем сказать - насколько больше, насколько меньше.
      это позволит нам вычислять средние показатели разброс коэф корреляции и тд

    Более сильную шкалу можно рассматривать как более слабую, но не наоборот (в общем случае)

  Данные .
    Разделяются на:
    1. Одномерные .
      фиксируем 1 показатель
      непрерывные .
        - количественная .
      дискретные .
       МДЗ - представляет собой счетное множество.
        - количественная .
        - порядковая .
        - номинальная .
          * категоризованные .
          * некатегоризованные .
    -  Многомерные .
      фиксируем несколько показателей во время наблюдения
      являются совокупностью одномерных
  
    2. Временные .
    наблюдения величины в одной точке в разные моменты времени 
    -  Пространственные .
     наблюдения величины у разных объектов
    
  Вариационный ряд .
  это таблица построенная на основании некоторых количественных значений, гдще имеется достаточное количество повторов.

  Интервальный ряд .
  группируем выборку по интервалам и строим вариационный ряд на основании попадания в интервал.  



Оценка параметров и числовых характеристик .

Задача статистики:

 По наблюдениям за случайной величиной, то есть по выборке |Х1...Хn| построить представление 
 о законе ее распределения, о ее значениях, о мерах ее показателей - среднее, мере разброса и т.д.

Пусть есть параметр |Q| - какая то неизвестная величина.
|Q*|- его точечная оценка, полученная на основании выборки наблдений |x1... xn|
оценка - случайная величина, которая варьируется также как варьируется элементы выборки.
Но если выборка репрезентативна, а функция для получения оценки величины|Q|достаточно верна, то оценка дает 
хорошее представление о параметре.

  Оценка должна быть .
    * несмещенной .
    * состоятельной .
      Состоятельность оценки - с ростом выборки точность оценки улучшается.
    * эффективной .
      Дисперсия оценки минимальна

 Статистическая оценка неизвестного параметра - функция наблюдений.

  Числовые характеристики выборки- .
    средние показатели: .
    # среднее арифметическое
      сумма элементов деленая на объем выборки
    # среднее геометрическое
      произведение элементов в степени 1/n
    # среднее гармоническое
      объем выборки деленый на сумму обрытных  элементам выборки 
    # среднее квадратическое
      корень квадратный из суммы квадратов элементов деленых на объем выборки

  Меры вариации .
  (Характеристики разброса, рассеяния)    
  Разные величины при одном среднем значении могут иметь разный разброс. Для их оценки используются следующие меры:
    # Размах вариации R = xmax - xmin
      Не отражает внутреннего расположения точек - плотности распределения.
    # Среднее линейное отклонение
      d равное среднему арифметическому модулей разности элементов выборки и среднего значения.
    # Дисперсия 
      Если математическое ожидание изввестно МХ = mx:
      Дисперсия равна среднему арифметическому квадратов разности элементов выборки и мат ожидания. 
      Если мат ожидание неизвестно, то вместо него используется среднее арифметическое для выборки.
    # Среднеквадратическое отклонение - корень квадратный из дисперсии 
      возвращаемся к исходным единицам измерений. Эту величину намного проще интерпретировать. 
    # Коэффициент вариации (в процентах)
      Дает оценку однородности выборки.
      V равен среднеквадратическому отклонению деленому на среднее арифметическое и умноженное на 100.
      если V < 33% выборка однородна.

  Правило сложения дисперсий .
    Если измеряемый количественный показатель зависит от некоего качественного группирующего фактора, то
    дисперсии группирующих факторов и межгрупповая дисперсия в сумме дадут  дисперсию для всей выборки.

  На вопрос - Насколько сильно межгруповое отличие отвечает `коэффициент детерминации`
  отношение межгруповой дисперсии к общей дисперсии * 100%
  `корреляционное отношение` - корень квадратный из `коэффициента детерминации`
    Оценка связи по шкале Чеддока: .
  * |0|         - отсутствует
  * |(0, 0.2)|  - очень слабая
  * |[0.2, 0.3)|- слабая
  * |[0.3, 0.5)|- умеренная
  * |[0.5, 0.7)|- заметная
  * |[0.7, 0.9)| - сильная
  * |[0.9, 1)|   - очень сильная 
  * |1|          - функциональная

  Мода и медиана .
    Мода - наивероятнейшее значение случайнов величины .
      могут быть унимодальные и мультимодальные выборки.
    Медиана -  число которое делит вариационный ряд на 2 части содержащие равное количество наблюдений .
    для интервальной выборки`Мо`- сумма нижней границы интервала содержащего наибольшее количество наблюдений и
    произведения величины модального интервала на следующее отношение:
  |        N(m) - N(m-1) 
  | ___________________________
  |  (N(m)-N(m-1))+(N(m)-N(m+1))  ; где
 `N(m)` количесчтво элементов выборки в интервале с амаксимальным количеством наблюдений
 `N(m-1), N(m+1)` количество элементов выборки в соседних интервалах

  Коэффициент ассиметрии .
    симметричность относительно вершины.


  Коэффициент эксцесса .
    Островершинность/плосковершинность или крутизна веток.

  Эти коэффициенты позволяют говорить о симметричности( или о право(лево)сторонний ассиметричности выборки)

  `Критерий Жарка-Берра`позволяет судить по этим коэффициентам о нормальности выборки.
  В регрессионноми анализе используется этот критерий.

  Квантиль порядка p .
    случайной величины х называется действительное число Хр такое, что вероятность того что случайная величина примет значение 
    меньше Хр будет в точности равна р. |Р(Х<Xp) = p|
  | Квантиль - величина теоретическая.
    Квантиль порядка 0.5 - медиана .

  Перцентиль - это оценка квантиля .
  | - относительная позиция варианты в ряду.
    р-й процентиль вариационного ряда - значение признака, слева от которого лежат р% вариант ряда.

  Квартили (1й, 2й, 3й) .
  | Значения делящие вариационный ряд на 4 равновероятные части. Т е в каждой части содержится 25% вариант ряда.

  Межкавртильное расстояние(Q3-Q1) .
  | Содержит 50% наблюдений, таких, что 25% меньше них а 25% - больше
  | Q2 - медиана, 50-й перцентиль

  Диаграмма размаха .
  строится на основе квартилей и помогает находить выбросы и экстремальные точки.

  Интервальная оценка .
    Доверительным интервалом для параметра`T`называется интервал`(Т1, Т2)`, содержащий истинное значение параметра
    с заданной вероятностью`р = 1 - а`то есть `P(Т1<T<T2)= 1 - a`  
  | р = 1 - а - это доверительная вероятность(надежность) оценки.
  | a - уровень значимости, вероятность с которой мы готовы допустить ошибку 


ПРОВЕРКА СТАТИСТИЧЕСКИХ ГИПОТЕЗ .

  Статистической гипотезой .
    называется некоторое предположение о виде неизвестного распределения наблюдаемых величин либо о значениях их параметров .
  Нулевая гипотеза .
    Основное высказываемое предположение, которое необходимо принять или отвергнуть на основании наблюдений в соответствии с выбранным критерием .
    Нулевая гипотеза обозначается|Н0|
  Альтернативная гипотеза .
    Предположение, противоположное нулевой гипотезе, которое принимается, если отклоняется нулевая гипотеза .
    Альтернативаня гипотеза обозначается|H1| 

  Ошибки при проверке гипотез: .

    Ошибка первого рода .
      заключается в том, что будет отвергнута справедливая нулевая гипотеза .
  
    Ошибка второго рода .
      заключается в том, что будет принята неправильная нулевая гипотеза .

    Вероятность ошибки первого рода`a = P(H1|H0)`
    Вероятность ошибки второго рода`b = P(H0|H1)` 
    `a`- уровень значимости. Обчно он равень`0.05 0.01 ...`
    Мощность критерия -`P(H1|H1) = 1-b`
    Для заданного`а`с помощью квартильной функции(в таблицах или функция пайтон к примеру) что с вероятностью 
    `1-а`будет выноситься решение в пользу`Н0`
    Наиболее мощный критерий - тот, который при фиксированной`а`даст минимальное значение`b`

| Z - статистика (функция наблюдений)
| V - область ее значений.
  Тогда:
    Критическая область Vk .
      называют совокупность значений статистики Z соответствующей критерию К при которых нулевую гипотезу Н0 отклоняют .
    Область принятия гипотезы (V\Vk) .
      совокупность значений статистики Z, соответствующей критерию K? при которых решение выносят в пользу нулевой гипотезы .

  | Таким образом задача - разбить область возможных значений V статистики Z на критическую область и область принятия решений    
    Zкр - точки, являющиеся границами критической области .
    Различают левостороннюю, правостороннюю и двустороннюю критические области.

  Алгоритм проверки гипотез: .
    1. Формулируем нулевую и альтернативнуюгипотезы с ориентацией на конкретный критерий .
       Нулевая гипотеза - отсутствие эффекта, альтернативная - наличие эффекта.
       Выбирается критерий`К`и соответствующая ему статистика`Z`табличное значение)
    2. Определяется распределение статистики Z в предположении, что гипотеза Н0 верна .
       На самом деле статистика задана изначально (ну да, вот так) 
    3. Задается уровень значимости а .
       По умолчанию 5% или 0.05 
    4. Определяются границы критической области, соответствующие выбранному уровню значимости и критерию .
       При классическом подходе(через таблицы), иначе при использовании програмных продуктов мы получим специальный параметр "пи-велью"
       для оценки гипотезы. 
    5. По выборке вычисляется выборочное(наблюдаемое) значение статистики Zb .
    6. Если выборочное значение попадает в область принятия гипотезы - решение выносят в пользу гипотезы H0 .
       в противном случае - если наблюдаемое значение попало в критическую область - гипотезу Н0 отвергают в пользу гипотезы Н1 

  Например .
    критерий согласия Пирсона .
    На основании наблюдений `Х: х1...xn`
    проверяется гипотеза о том. что ее закон распределения `Fx(x)` соответствует некоторому заданному закону `F0(x)`

    1. Переходим к интервальной выборке, строим гистограмму и подсчитываем сколько элементов выборки попало в каждый интервал - `ni`
    | Х^2 = сумма(ni-vi)^2/vi 
      статистика хи квадрат описывает несоответствие нашей выборки теоретическому закону распределения .
    | vi - теоретические частоты 
    2. Находим критическое значение - такое максимальное значение, при котором распределения согласованы.
    Берем таблицу распределения хи квадрат, задаем - а - уровень значимости и на основании числа `степеней свободы` (количество интервалов-1)
    находим`критическое значение`
    и сравнивая вычесленное значение хи квадрат с полученным критическим значением делаем вывод о истинности нулевой гипотезы. 
    `Хкрит`- максимальная величина при которой гипотеза`Н0`принимается. Чем больше разница между`Х`и`Хкр` - тем с большей вероятностью мы 
    можем утверждать о соответствии(или несоответствии) распределений.

    При програмных расчетах:
      будет вычеслено`p-value` - вероятность того, что мы получим на какой то выборке из генеральной совокупности значение статистики 
      превышающее`Хкрит`
    | p-value > a  принимаем Н0
    чем больше разница p-value и a тем надежнее мы можем утверждать о истиности принятой гипотезы. 

  Библиотеки scypy и scypy.stats .
    Используются для проверки статистических гиппотез .
      1. загружаем файл с датасетом .
      2. Проверяем датасет на пропуски, удаляем или заполняем их .
      3. Строим гистограмму для количественных значений .
         смотрим ассиметричность, нормальность
      4. Смотрим статистики .
         Обращаем внимание, для каких столбцов имеют смысл эти статистики (среднее, минимальное, прецентили)
      5. Строим боксплоты, обрабатываем выбросы .
      6. Считаем среднеквадратическое отклонение, коэффициенты эксцесса и ассиметрии .
      7. Проверка нормальности по критерию Шапиро-Уилка .
      | stats.shapiro(ds.column) -
        возвращает |(значение статистики, p-value)| 
        если |p-value < a| нулевая гипотеза о нормальности распределения отвергается в пользу альтернативной.

    Анализ влияния категориальных признаков. Критерии сравнения групп .
      1. Группируем данные по категориальному признаку .
      2. Вычисляем среднее(например) значение по количественному признаку для групп .

Критерии сравнения групп .
  Данные количественные и нормальные .
    Параметрические критерии .
      Групп 2 .
        критерий Фишера .
          проверяет равенство дисперсий
        t критерий Стьюдента .
          дисперсии должны быть равны
          проверяем гипотезу о равенстве средних 
      Групп > 2 .
        Дисперсионный анализ (ANOVA) .
        дисперсии должны быть равны
        проверяем гипотезу о равенстве средних
  Данные количественные но не соотв нормальному распределению или порядковые(ранговые) .
    Непараметрические критерии .
      Групп 2 .
        Независимые .
          Вальда-Вольфовица .
          Колмогорова-Смирнова .
          Манна-Уитни .
          самый часто применяемый критерий
        Зависимые .
          Знаковый .
          Вилкоксона .
          самый часто применяемый для зависимых совокупностей.
      Групп > 2 .
        Независимые .
          Медианный .
          Краскала-Уолиса .
          Краскал - Уолис - ANOVA
        Зависимые .
          Фридмана .
          Тенденций Пейджа .
  Данные качественные .
          Хи квадрат .
          Точный критерий Фишера .

Практическое применение критериев сравнения групп .
  1. группируем по категориальному признаку: .
      гуппируем на этой основе по количественному показателю и находим например среднее:

  | ds.groupby('category')['quant'].mean()
  2. строим боксплоты .
  | fig = sns.boxplot(x='category', y='quant', data =ds)
  3. проверяем гипотезу о нормальности выборок .
     используя критерий шапиро-вилкса.
  |  stats.shapiro(filtred_group1)
      возвращает |(значение статистики, p-value)| 
      если |p-value < a| нулевая гипотеза о нормальности распределения отвергается в пользу альтернативной.
    
  4. Если отклонена гипоеза о нормальности распределения используем для 2 групп критерий Манна-Уитни .
    | stats.mannwhitneyu(group1, group2)  
    пролучаем статистику Манна Уитни и пи-велью.
    Нулевая гипотеза - средние показатели равны принимается если пи велью больше альфа .

Для 3+ групп алгоритм действий аналогичен: .
  1. Боксплоты, визуализация .
  2. Удалить выбросы .
  3. критерий Краскла - Уоллеса .
  | stats.kraskalwallis(group1, group2, group2, group4)
  аналогично получаем статистику и пи-велью
  на основе пи-велью принимаем или отклоняем нулевую гипотезу.
  

